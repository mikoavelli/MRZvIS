# Индивидуальная лабораторная работа 3 по дисциплине МРЗвИС вариант 6
# "Реализовать модель рекурентной сети с цепью нейросетевых моделей долгой кратковременной памяти
# с логарифмисечкой функциоей активации (гиперболический арксинус) выходного сигнала на скрытом слое"
# Выполнена студентом группы X БГУИР X X X
# Использованные источники:
# Формальные модели обработки информации и параллельные модели решения задач.
# Практикум: учебно-методическое пособие / В.П.Ивашенко. – Минск: БГУИР, 2020.

# --- Параметры данных ---
SEQ_LEN = 50  # Общая длина генерируемой последовательности (история)
FUTURE_STEPS = 5  # Горизонт прогнозирования (сколько шагов предсказываем вперед)
WINDOW_SIZE = 5  # Размер скользящего окна (сколько чисел подаем на вход за раз)

# --- Архитектура сети ---
INPUT_SIZE = 1  # Размерность входа (одно число за такт)
HIDDEN_SIZE = 16  # "Емкость" сети. Количество нейронов в скрытом слое (вектор h)
OUTPUT_SIZE = 1  # Размерность выхода (предсказываем одно число)

# --- Гиперпараметры обучения ---
LEARNING_RATE = 0.01  # Шаг градиентного спуска (скорость обучения)
EPOCHS = 1000  # Количество полных проходов по всей выборке
CLIP_VALUE = 5.0  # Порог для Gradient Clipping.
# Важно для RNN: если градиент > 5, он обрезается.
# Это спасает от проблемы "взрывающихся градиентов".

# --- Прочее ---
RANDOM_SEED = 42  # Фиксация генератора случайных чисел для воспроизводимости результатов
